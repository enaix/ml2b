# -*- coding: utf-8 -*-
"""cs506.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1gKwzGBeohyXV2ZgGCeQtgW05PYnwUszG
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix
from scipy.sparse import hstack, csr_matrix
import re
from datetime import datetime
import warnings
warnings.filterwarnings('ignore')


print("Loading data...")
df = pd.read_csv('train.csv')

print(f"Dataset shape: {df.shape}")
print(f"\nTarget distribution:\n{df['Score'].value_counts().sort_index()}")
print(f"\nMissing values:\n{df.isnull().sum()}")


def extract_features(df):
    df = df.copy()

    df['summary'] = df['summary'].fillna('')
    df['reviewText'] = df['reviewText'].fillna('')
    df['genres'] = df['genres'].fillna('')


    df['summary_length'] = df['summary'].apply(len)
    df['review_length'] = df['reviewText'].apply(len)
    df['word_count'] = df['reviewText'].apply(lambda x: len(str(x).split()))


    df['sentence_count'] = df['reviewText'].apply(lambda x: len(re.split(r'[.!?]+', str(x))))

    df['avg_word_length'] = df['reviewText'].apply(
        lambda x: np.mean([len(word) for word in str(x).split()]) if len(str(x).split()) > 0 else 0
    )

    df['capital_ratio'] = df['reviewText'].apply(
        lambda x: sum(1 for c in str(x) if c.isupper()) / len(str(x)) if len(str(x)) > 0 else 0
    )

    df['exclamation_count'] = df['reviewText'].apply(lambda x: str(x).count('!'))

    df['question_count'] = df['reviewText'].apply(lambda x: str(x).count('?'))

    df['genre_count'] = df['genres'].apply(lambda x: len(str(x).split(',')) if pd.notna(x) and str(x) != '' else 0)

    df['VotedHelpful'] = df['VotedHelpful'].fillna(0)
    df['TotalVotes'] = df['TotalVotes'].fillna(0)

    df['helpful_ratio'] = df.apply(
        lambda row: row['VotedHelpful'] / row['TotalVotes'] if row['TotalVotes'] > 0 else 0, axis=1
    )

    df['unixReviewTime'] = df['unixReviewTime'].fillna(df['unixReviewTime'].median())
    df['review_year'] = df['unixReviewTime'].apply(lambda x: datetime.fromtimestamp(x).year if pd.notna(x) else 2010)
    df['review_month'] = df['unixReviewTime'].apply(lambda x: datetime.fromtimestamp(x).month if pd.notna(x) else 6)
    df['review_day_of_week'] = df['unixReviewTime'].apply(lambda x: datetime.fromtimestamp(x).weekday() if pd.notna(x) else 0)
    df['review_hour'] = df['unixReviewTime'].apply(lambda x: datetime.fromtimestamp(x).hour if pd.notna(x) else 12)

    for col in ['reviewerID', 'album_mbid', 'artist_mbid']:
        if col in df.columns:
            df[col] = df[col].fillna('unknown')
            freq = df[col].value_counts().to_dict()
            df[f'{col}_freq'] = df[col].map(freq)

    return df

print("\nFeature engineering...")
df_processed = extract_features(df)

print("Creating TF-IDF features...")

df_processed['combined_text'] = df_processed['summary'] + ' ' + df_processed['reviewText']

tfidf_text = TfidfVectorizer(
    max_features=500,
    min_df=3,
    max_df=0.8,
    ngram_range=(1, 2),
    stop_words='english',
    sublinear_tf=True
)

text_features = tfidf_text.fit_transform(df_processed['combined_text'])

tfidf_genres = TfidfVectorizer(max_features=50, token_pattern=r'[^,]+')
genre_features = tfidf_genres.fit_transform(df_processed['genres'].fillna(''))

numeric_features = [
    'VotedHelpful', 'TotalVotes', 'helpful_ratio',
    'summary_length', 'review_length', 'word_count',
    'sentence_count', 'avg_word_length', 'capital_ratio',
    'exclamation_count', 'question_count', 'genre_count',
    'review_year', 'review_month', 'review_day_of_week', 'review_hour',
    'reviewerID_freq', 'album_mbid_freq', 'artist_mbid_freq'
]

numeric_data = df_processed[numeric_features].fillna(0).values

print("Combining all features...")

X = hstack([
    csr_matrix(numeric_data),
    text_features,
    genre_features
])

y = df_processed['Score'].values
y_original = y.copy()
y = y - 1

print(f"\nFinal feature matrix shape: {X.shape}")
print(f"Target shape: {y.shape}")
print(f"Target classes: {np.unique(y)} (transformed from {np.unique(y_original)})")

print("\n" + "="*50)
print("CREATING TRAIN-VALIDATION SPLIT")
print("="*50)

stratified_split = True

X_train, X_val, y_train, y_val = train_test_split(
    X, y,
    test_size=0.2,
    random_state=42,
    shuffle=True,
    stratify=y if stratified_split else None
)

print(f"Train set size: {X_train.shape[0]}")
print(f"Validation set size: {X_val.shape[0]}")
print(f"\nTrain target distribution:\n{pd.Series(y_train).value_counts().sort_index()}")
print(f"\nValidation target distribution:\n{pd.Series(y_val).value_counts().sort_index()}")

print("\n" + "="*50)
print("TRAINING MODELS")
print("="*50)

models = {}
predictions = {}

# 1. Logistic Regression
print("\n1. Training Logistic Regression...")
lr = LogisticRegression(
    max_iter=1000,
    random_state=42,
    C=1.0,
    class_weight='balanced',
    solver='lbfgs'
)
lr.fit(X_train, y_train)
models['LogisticRegression'] = lr

y_pred_lr = lr.predict(X_val)
predictions['LogisticRegression'] = y_pred_lr
print(f"✓ LR - Accuracy: {accuracy_score(y_val, y_pred_lr):.4f}")
print(f"✓ LR - F1 Score (macro): {f1_score(y_val, y_pred_lr, average='macro'):.4f}")
print(f"✓ LR - F1 Score (weighted): {f1_score(y_val, y_pred_lr, average='weighted'):.4f}")

# 2. Random Forest
print("\n2. Training Random Forest...")
rf = RandomForestClassifier(
    class_weight='balanced'
)
rf.fit(X_train, y_train)
models['RandomForest'] = rf

y_pred_rf = rf.predict(X_val)
predictions['RandomForest'] = y_pred_rf
print(f"✓ RF - Accuracy: {accuracy_score(y_val, y_pred_rf):.4f}")
print(f"✓ RF - F1 Score (macro): {f1_score(y_val, y_pred_rf, average='macro'):.4f}")
print(f"✓ RF - F1 Score (weighted): {f1_score(y_val, y_pred_rf, average='weighted'):.4f}")

print("\n" + "="*50)
print("MODEL COMPARISON & EVALUATION")
print("="*50)

results = {}
for name, y_pred in predictions.items():
    results[name] = {
        'accuracy': accuracy_score(y_val, y_pred),
        'f1_weighted': f1_score(y_val, y_pred, average='weighted'),
        'f1_macro': f1_score(y_val, y_pred, average='macro')
    }

print("\nModel Performance Summary:")
print("-" * 70)
print(f"{'Model':<25} {'Accuracy':<12} {'F1 (weighted)':<15} {'F1 (macro)':<12}")
print("-" * 70)
for name, metrics in results.items():
    print(f"{name:<25} {metrics['accuracy']:<12.4f} {metrics['f1_weighted']:<15.4f} {metrics['f1_macro']:<12.4f}")
print("-" * 70)

best_model_name = max(results, key=lambda x: results[x]['f1_macro'])
best_model = models[best_model_name]
y_pred_best = predictions[best_model_name]