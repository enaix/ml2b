# -*- coding: utf-8 -*-
"""emnist.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1vzpJuL4yBIr9Cp2nTTUpnTwfgqkxFevl
"""

import os
import random
import numpy as np
import tensorflow as tf


# Set seeds for reproducibility
def set_seeds(seed=42):
    os.environ['PYTHONHASHSEED'] = str(seed)
    random.seed(seed)
    np.random.seed(seed)
    tf.random.set_seed(seed)

set_seeds(42)
os.environ["TF_DETERMINISTIC_OPS"] = "1"
os.environ["TF_CUDNN_DETERMINISTIC"] = "1"

# -------------------------------
# Baseline
# EMNIST Competition
# -------------------------------
import pandas as pd
from sklearn.model_selection import train_test_split
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout
from tensorflow.keras.utils import to_categorical
from sklearn.metrics import accuracy_score

# ===============================
# Load data
# ===============================
train_data = np.load("/content/train.npz")  # adjust path if needed
X = train_data["images"]
y = train_data["labels"]
X = np.squeeze(X, axis=-1)
y = np.squeeze(y, axis=-1)

# ===============================
# Train / Test split
# ===============================
X_train, X_test, y_train, y_test = train_test_split(
    X,
    y,
    test_size=0.2,
    random_state=42,
    shuffle=True
)

# ===============================
# Preprocessing
# ===============================
X_train = X_train.astype("float32") / 255.0
X_test  = X_test.astype("float32") / 255.0

X_train = X_train[..., np.newaxis]
X_test  = X_test[..., np.newaxis]

num_classes = 62
y_train_cat = to_categorical(y_train, num_classes)

# ===============================
# Model
# ===============================
model = Sequential([
    Conv2D(32, (3, 3), activation="relu", input_shape=(28, 28, 1)),
    MaxPooling2D((2, 2)),

    Conv2D(64, (3, 3), activation="relu"),
    MaxPooling2D((2, 2)),

    Flatten(),
    Dense(128, activation="relu"),
    Dropout(0.5),
    Dense(num_classes, activation="softmax")
])

model.compile(
    optimizer="adam",
    loss="categorical_crossentropy",
    metrics=["accuracy"]
)

model.summary()

# ===============================
# Train
# ===============================
model.fit(
    X_train,
    y_train_cat,
    epochs=50,
    batch_size=128,
    verbose=1
)

# ===============================
# Evaluate on test
# ===============================
test_preds = model.predict(X_test)
test_labels = np.argmax(test_preds, axis=1)

acc = accuracy_score(y_test, test_labels)
print(f"Test accuracy: {acc:.5f}")