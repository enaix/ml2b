{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "1b0c748e-9ac2-47e9-ba8e-a1b2489cdab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "cef3d719-8b36-44f3-ab01-6356308b0ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fname = \"file_analysis_results2.csv\"\n",
    "fname = \"modular-1.csv\"\n",
    "df = pd.read_csv(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "7b6b689b-186d-4baa-914c-7ccf7a81a132",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>python_file_path</th>\n",
       "      <th>html_file_path</th>\n",
       "      <th>original_file_path</th>\n",
       "      <th>entrypoint_status</th>\n",
       "      <th>error_status</th>\n",
       "      <th>traceback</th>\n",
       "      <th>preprocessing_leakage</th>\n",
       "      <th>overlap_leakage</th>\n",
       "      <th>no_independence</th>\n",
       "      <th>highlight_lines</th>\n",
       "      <th>mark_leak_lines</th>\n",
       "      <th>warnings</th>\n",
       "      <th>funcs_info</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FILES/modular-1-flat/gpt-4.1-mini_Arab_wids-da...</td>\n",
       "      <td>FILES/modular-1-flat/gpt-4.1-mini_Arab_wids-da...</td>\n",
       "      <td>/home/student/imposter/leakage-analysis/FILES/...</td>\n",
       "      <td>ENTRYPOINT_NOT_ADDED</td>\n",
       "      <td>CODE_PARSE_SUCCESS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FILES/modular-1-flat/gemini-2.5-flash_Japanese...</td>\n",
       "      <td>FILES/modular-1-flat/gemini-2.5-flash_Japanese...</td>\n",
       "      <td>/home/student/imposter/leakage-analysis/FILES/...</td>\n",
       "      <td>ENTRYPOINT_NOT_ADDED</td>\n",
       "      <td>CODE_PARSE_SUCCESS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[115, 156, 115, 156]</td>\n",
       "      <td>[]</td>\n",
       "      <td>['no independent test data']</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FILES/modular-1-flat/gemini-2.5-flash_Belarus_...</td>\n",
       "      <td>FILES/modular-1-flat/gemini-2.5-flash_Belarus_...</td>\n",
       "      <td>/home/student/imposter/leakage-analysis/FILES/...</td>\n",
       "      <td>ENTRYPOINT_NOT_ADDED</td>\n",
       "      <td>CODE_PARSE_SUCCESS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[162, 241, 162, 241]</td>\n",
       "      <td>[]</td>\n",
       "      <td>['no independent test data']</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FILES/modular-1-flat/gemini-2.5-flash_Romanian...</td>\n",
       "      <td>FILES/modular-1-flat/gemini-2.5-flash_Romanian...</td>\n",
       "      <td>/home/student/imposter/leakage-analysis/FILES/...</td>\n",
       "      <td>ENTRYPOINT_NOT_ADDED</td>\n",
       "      <td>CODE_PARSE_SUCCESS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[125, 80, 125, 80]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FILES/modular-1-flat/gemini-2.5-flash_Romanian...</td>\n",
       "      <td>FILES/modular-1-flat/gemini-2.5-flash_Romanian...</td>\n",
       "      <td>/home/student/imposter/leakage-analysis/FILES/...</td>\n",
       "      <td>ENTRYPOINT_NOT_ADDED</td>\n",
       "      <td>CODE_PARSE_SUCCESS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[109, 112, 206, 109, 112, 206, 109, 112, 206]</td>\n",
       "      <td>[45, 46]</td>\n",
       "      <td>['potential preprocessing leakage']</td>\n",
       "      <td>[{'name': 'train', 'args': ['X_train', 'y_trai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>560</th>\n",
       "      <td>FILES/modular-1-flat/gpt-oss-120_Italian_she-h...</td>\n",
       "      <td>FILES/modular-1-flat/gpt-oss-120_Italian_she-h...</td>\n",
       "      <td>/home/student/imposter/leakage-analysis/FILES/...</td>\n",
       "      <td>ENTRYPOINT_NOT_ADDED</td>\n",
       "      <td>CODE_PARSE_SUCCESS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[38, 69, 38, 69]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>561</th>\n",
       "      <td>FILES/modular-1-flat/gemini-2.5-flash_Turkish_...</td>\n",
       "      <td>FILES/modular-1-flat/gemini-2.5-flash_Turkish_...</td>\n",
       "      <td>/home/student/imposter/leakage-analysis/FILES/...</td>\n",
       "      <td>ENTRYPOINT_NOT_ADDED</td>\n",
       "      <td>CODE_PARSE_SUCCESS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[32, 67, 32, 67]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>562</th>\n",
       "      <td>FILES/modular-1-flat/gemini-2.5-flash_English_...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/home/student/imposter/leakage-analysis/FILES/...</td>\n",
       "      <td>ENTRYPOINT_NOT_ADDED</td>\n",
       "      <td>FATAL_ERROR</td>\n",
       "      <td>e=SyntaxError('invalid syntax', ('&lt;unknown&gt;', ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>563</th>\n",
       "      <td>FILES/modular-1-flat/gpt-4.1-mini_Japanese_ieo...</td>\n",
       "      <td>FILES/modular-1-flat/gpt-4.1-mini_Japanese_ieo...</td>\n",
       "      <td>/home/student/imposter/leakage-analysis/FILES/...</td>\n",
       "      <td>ENTRYPOINT_NOT_ADDED</td>\n",
       "      <td>CODE_PARSE_SUCCESS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>FILES/modular-1-flat/gpt-4.1-mini_English_she-...</td>\n",
       "      <td>FILES/modular-1-flat/gpt-4.1-mini_English_she-...</td>\n",
       "      <td>/home/student/imposter/leakage-analysis/FILES/...</td>\n",
       "      <td>ENTRYPOINT_NOT_ADDED</td>\n",
       "      <td>CODE_PARSE_SUCCESS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[35, 92, 35, 92]</td>\n",
       "      <td>[]</td>\n",
       "      <td>['no independent test data']</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>565 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      python_file_path  \\\n",
       "0    FILES/modular-1-flat/gpt-4.1-mini_Arab_wids-da...   \n",
       "1    FILES/modular-1-flat/gemini-2.5-flash_Japanese...   \n",
       "2    FILES/modular-1-flat/gemini-2.5-flash_Belarus_...   \n",
       "3    FILES/modular-1-flat/gemini-2.5-flash_Romanian...   \n",
       "4    FILES/modular-1-flat/gemini-2.5-flash_Romanian...   \n",
       "..                                                 ...   \n",
       "560  FILES/modular-1-flat/gpt-oss-120_Italian_she-h...   \n",
       "561  FILES/modular-1-flat/gemini-2.5-flash_Turkish_...   \n",
       "562  FILES/modular-1-flat/gemini-2.5-flash_English_...   \n",
       "563  FILES/modular-1-flat/gpt-4.1-mini_Japanese_ieo...   \n",
       "564  FILES/modular-1-flat/gpt-4.1-mini_English_she-...   \n",
       "\n",
       "                                        html_file_path  \\\n",
       "0    FILES/modular-1-flat/gpt-4.1-mini_Arab_wids-da...   \n",
       "1    FILES/modular-1-flat/gemini-2.5-flash_Japanese...   \n",
       "2    FILES/modular-1-flat/gemini-2.5-flash_Belarus_...   \n",
       "3    FILES/modular-1-flat/gemini-2.5-flash_Romanian...   \n",
       "4    FILES/modular-1-flat/gemini-2.5-flash_Romanian...   \n",
       "..                                                 ...   \n",
       "560  FILES/modular-1-flat/gpt-oss-120_Italian_she-h...   \n",
       "561  FILES/modular-1-flat/gemini-2.5-flash_Turkish_...   \n",
       "562                                                NaN   \n",
       "563  FILES/modular-1-flat/gpt-4.1-mini_Japanese_ieo...   \n",
       "564  FILES/modular-1-flat/gpt-4.1-mini_English_she-...   \n",
       "\n",
       "                                    original_file_path     entrypoint_status  \\\n",
       "0    /home/student/imposter/leakage-analysis/FILES/...  ENTRYPOINT_NOT_ADDED   \n",
       "1    /home/student/imposter/leakage-analysis/FILES/...  ENTRYPOINT_NOT_ADDED   \n",
       "2    /home/student/imposter/leakage-analysis/FILES/...  ENTRYPOINT_NOT_ADDED   \n",
       "3    /home/student/imposter/leakage-analysis/FILES/...  ENTRYPOINT_NOT_ADDED   \n",
       "4    /home/student/imposter/leakage-analysis/FILES/...  ENTRYPOINT_NOT_ADDED   \n",
       "..                                                 ...                   ...   \n",
       "560  /home/student/imposter/leakage-analysis/FILES/...  ENTRYPOINT_NOT_ADDED   \n",
       "561  /home/student/imposter/leakage-analysis/FILES/...  ENTRYPOINT_NOT_ADDED   \n",
       "562  /home/student/imposter/leakage-analysis/FILES/...  ENTRYPOINT_NOT_ADDED   \n",
       "563  /home/student/imposter/leakage-analysis/FILES/...  ENTRYPOINT_NOT_ADDED   \n",
       "564  /home/student/imposter/leakage-analysis/FILES/...  ENTRYPOINT_NOT_ADDED   \n",
       "\n",
       "           error_status                                          traceback  \\\n",
       "0    CODE_PARSE_SUCCESS                                                NaN   \n",
       "1    CODE_PARSE_SUCCESS                                                NaN   \n",
       "2    CODE_PARSE_SUCCESS                                                NaN   \n",
       "3    CODE_PARSE_SUCCESS                                                NaN   \n",
       "4    CODE_PARSE_SUCCESS                                                NaN   \n",
       "..                  ...                                                ...   \n",
       "560  CODE_PARSE_SUCCESS                                                NaN   \n",
       "561  CODE_PARSE_SUCCESS                                                NaN   \n",
       "562         FATAL_ERROR  e=SyntaxError('invalid syntax', ('<unknown>', ...   \n",
       "563  CODE_PARSE_SUCCESS                                                NaN   \n",
       "564  CODE_PARSE_SUCCESS                                                NaN   \n",
       "\n",
       "     preprocessing_leakage  overlap_leakage  no_independence  \\\n",
       "0                      0.0              0.0              0.0   \n",
       "1                      0.0              0.0              0.0   \n",
       "2                      0.0              0.0              1.0   \n",
       "3                      0.0              0.0              0.0   \n",
       "4                      1.0              0.0              0.0   \n",
       "..                     ...              ...              ...   \n",
       "560                    0.0              0.0              0.0   \n",
       "561                    0.0              0.0              0.0   \n",
       "562                    NaN              NaN              NaN   \n",
       "563                    0.0              0.0              0.0   \n",
       "564                    0.0              0.0              1.0   \n",
       "\n",
       "                                   highlight_lines mark_leak_lines  \\\n",
       "0                                               []              []   \n",
       "1                             [115, 156, 115, 156]              []   \n",
       "2                             [162, 241, 162, 241]              []   \n",
       "3                               [125, 80, 125, 80]              []   \n",
       "4    [109, 112, 206, 109, 112, 206, 109, 112, 206]        [45, 46]   \n",
       "..                                             ...             ...   \n",
       "560                               [38, 69, 38, 69]              []   \n",
       "561                               [32, 67, 32, 67]              []   \n",
       "562                                            NaN             NaN   \n",
       "563                                             []              []   \n",
       "564                               [35, 92, 35, 92]              []   \n",
       "\n",
       "                                warnings  \\\n",
       "0                                     []   \n",
       "1           ['no independent test data']   \n",
       "2           ['no independent test data']   \n",
       "3                                     []   \n",
       "4    ['potential preprocessing leakage']   \n",
       "..                                   ...   \n",
       "560                                   []   \n",
       "561                                   []   \n",
       "562                                  NaN   \n",
       "563                                   []   \n",
       "564         ['no independent test data']   \n",
       "\n",
       "                                            funcs_info  \n",
       "0                                                   []  \n",
       "1                                                   []  \n",
       "2                                                   []  \n",
       "3                                                   []  \n",
       "4    [{'name': 'train', 'args': ['X_train', 'y_trai...  \n",
       "..                                                 ...  \n",
       "560                                                 []  \n",
       "561                                                 []  \n",
       "562                                                NaN  \n",
       "563                                                 []  \n",
       "564                                                 []  \n",
       "\n",
       "[565 rows x 13 columns]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "153dfad3-2c5c-4142-b3d0-e05f849ae81e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>python_file_path</th>\n",
       "      <th>html_file_path</th>\n",
       "      <th>original_file_path</th>\n",
       "      <th>entrypoint_status</th>\n",
       "      <th>error_status</th>\n",
       "      <th>traceback</th>\n",
       "      <th>preprocessing_leakage</th>\n",
       "      <th>overlap_leakage</th>\n",
       "      <th>no_independence</th>\n",
       "      <th>highlight_lines</th>\n",
       "      <th>mark_leak_lines</th>\n",
       "      <th>warnings</th>\n",
       "      <th>funcs_info</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>FILES/modular-1-flat/gemini-2.5-flash_Russian_...</td>\n",
       "      <td>FILES/modular-1-flat/gemini-2.5-flash_Russian_...</td>\n",
       "      <td>/home/student/imposter/leakage-analysis/FILES/...</td>\n",
       "      <td>ENTRYPOINT_ADDED</td>\n",
       "      <td>CODE_PARSE_SUCCESS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[238, 253, 238, 253, 274, 320, 274, 320]</td>\n",
       "      <td>[]</td>\n",
       "      <td>['overlap with all test data', 'no independent...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>FILES/modular-1-flat/gpt-oss-120_Japanese_she-...</td>\n",
       "      <td>FILES/modular-1-flat/gpt-oss-120_Japanese_she-...</td>\n",
       "      <td>/home/student/imposter/leakage-analysis/FILES/...</td>\n",
       "      <td>ENTRYPOINT_NOT_ADDED</td>\n",
       "      <td>CODE_PARSE_SUCCESS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[79, 80, 79, 80]</td>\n",
       "      <td>[]</td>\n",
       "      <td>['overlap with all test data', 'no independent...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      python_file_path  \\\n",
       "70   FILES/modular-1-flat/gemini-2.5-flash_Russian_...   \n",
       "310  FILES/modular-1-flat/gpt-oss-120_Japanese_she-...   \n",
       "\n",
       "                                        html_file_path  \\\n",
       "70   FILES/modular-1-flat/gemini-2.5-flash_Russian_...   \n",
       "310  FILES/modular-1-flat/gpt-oss-120_Japanese_she-...   \n",
       "\n",
       "                                    original_file_path     entrypoint_status  \\\n",
       "70   /home/student/imposter/leakage-analysis/FILES/...      ENTRYPOINT_ADDED   \n",
       "310  /home/student/imposter/leakage-analysis/FILES/...  ENTRYPOINT_NOT_ADDED   \n",
       "\n",
       "           error_status traceback  preprocessing_leakage  overlap_leakage  \\\n",
       "70   CODE_PARSE_SUCCESS       NaN                    0.0              1.0   \n",
       "310  CODE_PARSE_SUCCESS       NaN                    0.0              1.0   \n",
       "\n",
       "     no_independence                           highlight_lines  \\\n",
       "70               0.0  [238, 253, 238, 253, 274, 320, 274, 320]   \n",
       "310              0.0                          [79, 80, 79, 80]   \n",
       "\n",
       "    mark_leak_lines                                           warnings  \\\n",
       "70               []  ['overlap with all test data', 'no independent...   \n",
       "310              []  ['overlap with all test data', 'no independent...   \n",
       "\n",
       "    funcs_info  \n",
       "70          []  \n",
       "310         []  "
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"overlap_leakage\"] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "753df9ff-670e-4cbd-b309-18c46e6f7fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop files with errors\n",
    "df_ok = df.dropna(subset=[\"html_file_path\"])\n",
    "df_ok[\"model\"] = df_ok[\"python_file_path\"].apply(lambda x: os.path.basename(x).split('_')[0])\n",
    "df_ok[\"model\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c4cd9e-73ad-4412-80ae-bceb249fce4f",
   "metadata": {},
   "source": [
    "## General information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "1ead4ee5-95cc-4a0e-9c5e-e3ff87a32824",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "554"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ok.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "276f8032-c89f-4a90-8c0f-b69be2a71e66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of files with preprocessing leakage\n",
    "n_leak = df_ok[df_ok[\"preprocessing_leakage\"] != 0].shape[0]\n",
    "n_leak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "40f37ce1-8933-462a-af99-ca45a477bd65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "493"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of files without preprocessing leakage\n",
    "n_not_leak = df_ok[df_ok[\"preprocessing_leakage\"] == 0].shape[0]\n",
    "n_not_leak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "8f204436-54e3-4395-a3de-0c6757c7e755",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11010830324909747"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Percentage of leakage\n",
    "n_leak / df_ok.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "31a46877-0867-41d1-a1fe-f7ef4e124bed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "warnings\n",
       "[]                                                                                                                                                                                                                                                                                                                                            274\n",
       "['no independent test data']                                                                                                                                                                                                                                                                                                                  166\n",
       "['no independent test data', 'no independent test data']                                                                                                                                                                                                                                                                                       27\n",
       "['potential preprocessing leakage']                                                                                                                                                                                                                                                                                                            25\n",
       "['no independent test data', 'potential preprocessing leakage']                                                                                                                                                                                                                                                                                17\n",
       "['no independent test data', 'no independent test data', 'used multiple times', 'used multiple times']                                                                                                                                                                                                                                          7\n",
       "['no independent test data', 'potential preprocessing leakage', 'potential preprocessing leakage']                                                                                                                                                                                                                                              7\n",
       "['potential preprocessing leakage', 'potential preprocessing leakage']                                                                                                                                                                                                                                                                          6\n",
       "['no independent test data', 'used multiple times']                                                                                                                                                                                                                                                                                             3\n",
       "['no independent test data', 'no independent test data', 'no independent test data']                                                                                                                                                                                                                                                            3\n",
       "['no independent test data', 'overlap with training data']                                                                                                                                                                                                                                                                                      3\n",
       "['no independent test data', 'used multiple times', 'used multiple times']                                                                                                                                                                                                                                                                      2\n",
       "['used multiple times']                                                                                                                                                                                                                                                                                                                         2\n",
       "['no independent test data', 'potential preprocessing leakage', 'used multiple times', 'potential preprocessing leakage', 'used multiple times']                                                                                                                                                                                                1\n",
       "['overlap with all test data', 'no independent test data', 'overlap with training data']                                                                                                                                                                                                                                                        1\n",
       "['no independent test data', 'potential preprocessing leakage', 'no independent test data', 'potential preprocessing leakage']                                                                                                                                                                                                                  1\n",
       "['no independent test data', 'potential preprocessing leakage', 'no independent test data', 'potential preprocessing leakage', 'overlap with training data', 'used multiple times', 'no independent test data', 'potential preprocessing leakage', 'potential preprocessing leakage', 'used multiple times', 'overlap with training data']      1\n",
       "['no independent test data', 'no independent test data', 'no independent test data', 'no independent test data']                                                                                                                                                                                                                                1\n",
       "['no independent test data', 'used multiple times', 'no independent test data', 'used multiple times']                                                                                                                                                                                                                                          1\n",
       "['used multiple times', 'used multiple times']                                                                                                                                                                                                                                                                                                  1\n",
       "['overlap with training data']                                                                                                                                                                                                                                                                                                                  1\n",
       "['potential preprocessing leakage', 'no independent test data']                                                                                                                                                                                                                                                                                 1\n",
       "['no independent test data', 'no independent test data', 'potential preprocessing leakage']                                                                                                                                                                                                                                                     1\n",
       "['overlap with all test data', 'no independent test data', 'overlap with training data', 'no independent test data']                                                                                                                                                                                                                            1\n",
       "['potential preprocessing leakage', 'no independent test data', 'potential preprocessing leakage']                                                                                                                                                                                                                                              1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"warnings\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "17cc2e82-a106-43c3-9497-8b80f29afa5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract information on functions with leakage\n",
    "funcs = df_ok[df_ok[\"preprocessing_leakage\"] != 0][\"funcs_info\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "b126384a-bd72-4374-8bae-07e4c9af9905",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[{'name': 'train', 'args': ['X_train', 'y_train'], 'start_line': 17, 'end_line': 131, 'contains_lines': [45, 46]}]\""
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "funcs.iloc[0]  # Example "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "5b8017ad-18d0-4227-a662-0333161b9962",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_json = lambda x: json.loads(x[\"funcs_info\"].replace(\"\\'\", \"\\\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "6ac89382-0aff-42e7-8004-fb112691a6d5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_26319/1595900398.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_ok[\"funcs_j\"] = df_ok.apply(load_json, axis=1)\n",
      "/tmp/ipykernel_26319/1595900398.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_ok[\"func_name\"] = df_ok.apply(lambda x: [f[\"name\"] for f in x[\"funcs_j\"]], axis=1)\n",
      "/tmp/ipykernel_26319/1595900398.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_ok[\"func_n_args\"] = df_ok.apply(lambda x: [len(f[\"args\"]) for f in x[\"funcs_j\"]], axis=1)\n",
      "/tmp/ipykernel_26319/1595900398.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_ok[\"n_funcs\"] = df_ok.apply(lambda x: len(x[\"funcs_j\"]), axis=1)\n",
      "/tmp/ipykernel_26319/1595900398.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_ok[\"func_sig\"] = df_ok.apply(lambda x: [f\"{f['name']}({f['args']})\" for f in x[\"funcs_j\"]], axis=1)\n"
     ]
    }
   ],
   "source": [
    "# Expand function metadata\n",
    "df_ok[\"funcs_j\"] = df_ok.apply(load_json, axis=1)\n",
    "df_ok[\"func_name\"] = df_ok.apply(lambda x: [f[\"name\"] for f in x[\"funcs_j\"]], axis=1)\n",
    "df_ok[\"func_n_args\"] = df_ok.apply(lambda x: [len(f[\"args\"]) for f in x[\"funcs_j\"]], axis=1)\n",
    "df_ok[\"n_funcs\"] = df_ok.apply(lambda x: len(x[\"funcs_j\"]), axis=1)\n",
    "df_ok[\"func_sig\"] = df_ok.apply(lambda x: [f\"{f['name']}({f['args']})\" for f in x[\"funcs_j\"]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "ac99d3f9-566e-43fb-bd62-05ce54d3b327",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "func_sig\n",
       "[train(['X_train', 'y_train'])]                                                      8\n",
       "[create_features(['df'])]                                                            5\n",
       "[add_features(['df'])]                                                               5\n",
       "[feature_engineer(['df'])]                                                           3\n",
       "[preprocess(['df', 'is_train', 'freq_encoders', 'dist_cap'])]                        1\n",
       "[add_features(['df', 'group_col'])]                                                  1\n",
       "[preprocess(['df', 'is_train'])]                                                     1\n",
       "[fit(['self', 'X', 'y'])]                                                            1\n",
       "[create_features(['df_input'])]                                                      1\n",
       "[_feature_engineer(['df'])]                                                          1\n",
       "[preprocess_features(['df', 'is_train', 'train_output'])]                            1\n",
       "[_prepare_features(['df', 'numeric_cols', 'categorical_cols', 'medians', 'fit'])]    1\n",
       "[preprocess(['df', 'imputer'])]                                                      1\n",
       "[engineer_features(['df'])]                                                          1\n",
       "[preprocess(['df', 'preprocessing_info', 'is_train'])]                               1\n",
       "[_feature_engineer(['df', 'is_train', 'train_output'])]                              1\n",
       "[_preprocess_features(['df', 'params', 'is_train'])]                                 1\n",
       "[build_features(['df'])]                                                             1\n",
       "[feature_engineering(['df', 'target_mean_enc', 'is_train'])]                         1\n",
       "[add_engineered_features(['df'])]                                                    1\n",
       "[preprocess_data(['df', 'fit', 'categorical_cols'])]                                 1\n",
       "[_replace_and_impute(['df', 'medians'])]                                             1\n",
       "[preprocess_numeric(['df', 'median_dict', 'scaler'])]                                1\n",
       "[_engineer_features(['df', 'is_train', 'fill_values'])]                              1\n",
       "[preprocess_features(['df', 'is_train', 'preprocessors'])]                           1\n",
       "[preprocess_data(['df', 'vectorizer', 'is_train'])]                                  1\n",
       "[_add_features(['df', 'max_lag', 'roll_window'])]                                    1\n",
       "[_create_features(['df_input'])]                                                     1\n",
       "[preprocess_features(['df', 'imputer', 'is_training', 'columns_to_use'])]            1\n",
       "[_impute_numerical_features(['df', 'imputation_modes', 'is_train'])]                 1\n",
       "[_preprocess_features(['df', 'is_train', 'preprocessors'])]                          1\n",
       "[preprocess(['df'])]                                                                 1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find cases where there is a single function with leakage\n",
    "df_ok[df_ok[\"n_funcs\"] == 1][\"func_sig\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "501f68e2-d975-4b89-8f14-badefee9eab7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "func_sig\n",
       "[fit(['self', 'X', 'y']), preprocess(['df'])]                                                                                                                                                                                                                                             1\n",
       "[create_aggregation_features(['X_df', 'is_train', 'train_agg_stats']), preprocess_features(['X_df', 'numerical_medians', 'categorical_features_list', 'is_train', 'numerical_missing_indicators'])]                                                                                       1\n",
       "[add_spatial_distance_feature(['df']), prepare_features(['df', 'target', 'te_maps', 'is_train', 'noise_level'])]                                                                                                                                                                          1\n",
       "[add_lag_and_cum_features(['df']), add_relative_time_features(['df']), add_rolling_features(['df', 'windows']), add_diff_features(['df'])]                                                                                                                                                1\n",
       "[target_encode_smooth(['train_series', 'target', 'valid_series', 'min_samples_leaf', 'smoothing', 'noise_level']), preprocess(['df', 'target', 'te_maps', 'is_train']), fit_target_encoding_maps(['df', 'target', 'cat_cols'])]                                                           1\n",
       "[preprocess(['df', 'is_train']), run(['X_train', 'y_train', 'X_val'])]                                                                                                                                                                                                                    1\n",
       "[add_target_encoding(['X', 'y', 'mapping', 'global_mean']), main([])]                                                                                                                                                                                                                     1\n",
       "[add_temporal_features(['df']), add_cumulative_features(['df']), add_breath_level_features(['df']), add_total_features(['df'])]                                                                                                                                                           1\n",
       "[target_mean_encoding_adaptive_smooth(['train_df', 'y', 'valid_df', 'col', 'n_splits', 'smoothing']), preprocess_basic(['df', 'is_train']), train(['X_train', 'y_train'])]                                                                                                                1\n",
       "[add_spatial_features(['df', 'pickup_zone_col', 'dropoff_zone_col', 'pickup_centroids', 'dropoff_centroids']), train(['X_train', 'y_train']), prepare_val(['X_val', 'train_output']), predict(['train_output', 'prepare_val_output'])]                                                    1\n",
       "[add_kfold_target_encoding(['df', 'y', 'categorical_cols', 'n_splits', 'smoothing', 'noise_level', 'seed']), preprocess(['df', 'freq_encoders', 'passenger_mode', 'vendor_mode', 'global_encodings', 'global_mean', 'is_train', 'drop_original_cats']), train(['X_train', 'y_train'])]    1\n",
       "[add_lag_features(['df']), add_diff_features(['df']), add_rolling_features(['df', 'window']), add_time_norm_feature(['df'])]                                                                                                                                                              1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cases where there is >1 function with leakage\n",
    "df_ok[df_ok[\"n_funcs\"] > 1][\"func_sig\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec2081d4-9b6e-45b0-88a1-1c99e041369e",
   "metadata": {},
   "source": [
    "## False-positive leakage analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "a7e982b6-a82d-4aac-9830-7192827ae974",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of trivial functions which accept a single argument\n",
    "df_1 = df_ok[df_ok[\"n_funcs\"] == 1]\n",
    "trivial_funcs = df_1[df_1[\"func_n_args\"].apply(lambda x: x[0] == 1)]\n",
    "trivial_funcs.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "55ece0e5-92c0-48d6-84e7-295a7e98db17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of train() functions\n",
    "train_funcs = df_1[df_1[\"func_name\"].apply(lambda x: x[0] == \"train\")]\n",
    "train_funcs.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "490e7488-2a4c-49a8-b4e1-3b4fa9bbb11c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Accept a single argument, but are not train()\n",
    "true_trivial = df_1[(df_1[\"func_n_args\"].apply(lambda x: x[0] == 1)) & (df_1[\"func_name\"].apply(lambda x: x[0] != \"train\"))]\n",
    "true_trivial.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "e5755887-9ceb-4b63-8b53-8b5b26eea8b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Total number of functions with this kind of false-positives\n",
    "fp_total = df_1[(df_1[\"func_n_args\"].apply(lambda x: x[0] == 1)) | (df_1[\"func_name\"].apply(lambda x: x[0] == \"train\"))]\n",
    "fp_total.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "6bdf5141-6acb-4e45-9481-00edd39b86b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.45901639344262296"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Percentage of trivial false-positives\n",
    "(fp_total.shape[0]) / n_leak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "58ec3781-dd8b-456c-8de6-4d85f86807df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remaining\n",
    "leak_rem = n_leak - fp_total.shape[0]\n",
    "leak_rem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "4406b2a8-03d7-42f0-b38d-4471a071b072",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05956678700361011"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Final percentage of true data leakage\n",
    "leak_rem / df_ok.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f36617a1-126b-45a8-8c9d-4d068bc061e7",
   "metadata": {},
   "source": [
    "## Analyzing the remaining leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "665e09b1-9a29-4980-a81c-6c4def7dfbad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_leak = df_ok[df_ok[\"preprocessing_leakage\"] != 0].drop(index=fp_total.index)\n",
    "df_leak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671d3459-bde3-4ffc-90f7-b19f304450d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ok[\"model\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6fb39ec-feb4-414f-b348-04b0fc6fd15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_leak[\"model\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "8cff1dba-404b-4ec1-91d1-53904f82464c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========= FUNCS INSPECTION ==========\n",
    "#        Manual code inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "5796cc17-52ca-45a4-ad1e-fac2120df19e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "func_sig\n",
       "[fit(['self', 'X', 'y']), preprocess(['df'])]                                                                                                                                                                                                                                             1\n",
       "[create_aggregation_features(['X_df', 'is_train', 'train_agg_stats']), preprocess_features(['X_df', 'numerical_medians', 'categorical_features_list', 'is_train', 'numerical_missing_indicators'])]                                                                                       1\n",
       "[add_spatial_distance_feature(['df']), prepare_features(['df', 'target', 'te_maps', 'is_train', 'noise_level'])]                                                                                                                                                                          1\n",
       "[add_lag_and_cum_features(['df']), add_relative_time_features(['df']), add_rolling_features(['df', 'windows']), add_diff_features(['df'])]                                                                                                                                                1\n",
       "[target_encode_smooth(['train_series', 'target', 'valid_series', 'min_samples_leaf', 'smoothing', 'noise_level']), preprocess(['df', 'target', 'te_maps', 'is_train']), fit_target_encoding_maps(['df', 'target', 'cat_cols'])]                                                           1\n",
       "[preprocess(['df', 'is_train']), run(['X_train', 'y_train', 'X_val'])]                                                                                                                                                                                                                    1\n",
       "[add_target_encoding(['X', 'y', 'mapping', 'global_mean']), main([])]                                                                                                                                                                                                                     1\n",
       "[add_temporal_features(['df']), add_cumulative_features(['df']), add_breath_level_features(['df']), add_total_features(['df'])]                                                                                                                                                           1\n",
       "[target_mean_encoding_adaptive_smooth(['train_df', 'y', 'valid_df', 'col', 'n_splits', 'smoothing']), preprocess_basic(['df', 'is_train']), train(['X_train', 'y_train'])]                                                                                                                1\n",
       "[add_spatial_features(['df', 'pickup_zone_col', 'dropoff_zone_col', 'pickup_centroids', 'dropoff_centroids']), train(['X_train', 'y_train']), prepare_val(['X_val', 'train_output']), predict(['train_output', 'prepare_val_output'])]                                                    1\n",
       "[add_kfold_target_encoding(['df', 'y', 'categorical_cols', 'n_splits', 'smoothing', 'noise_level', 'seed']), preprocess(['df', 'freq_encoders', 'passenger_mode', 'vendor_mode', 'global_encodings', 'global_mean', 'is_train', 'drop_original_cats']), train(['X_train', 'y_train'])]    1\n",
       "[add_lag_features(['df']), add_diff_features(['df']), add_rolling_features(['df', 'window']), add_time_norm_feature(['df'])]                                                                                                                                                              1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ok[df_ok[\"n_funcs\"] > 1][\"func_sig\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "9cb6d687-029a-4aad-8c19-018cda5c85df",
   "metadata": {},
   "outputs": [],
   "source": [
    "LEAK_SIGS = [\n",
    "    [\"preprocess(['df', 'is_train', 'freq_encoders', 'dist_cap'])\"],\n",
    "    [\"add_features(['df', 'group_col'])\"],\n",
    "    [\"preprocess_features(['df', 'is_train', 'train_output'])\"],\n",
    "    [\"_prepare_features(['df', 'numeric_cols', 'categorical_cols', 'medians', 'fit'])\"],\n",
    "    [\"preprocess_data(['df', 'fit', 'categorical_cols'])\"],\n",
    "    [\"preprocess_numeric(['df', 'median_dict', 'scaler'])\"],\n",
    "    [\"_preprocess_features(['df', 'is_train', 'preprocessors'])\"],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "4a06fa88-939d-4362-9ebe-cbf1beacab84",
   "metadata": {},
   "outputs": [],
   "source": [
    "LEAK_SIGS_2 = [\n",
    "    [\"fit(['self', 'X', 'y'])\", \"preprocess(['df'])\"],\n",
    "    [\"add_spatial_distance_feature(['df'])\", \"prepare_features(['df', 'target', 'te_maps', 'is_train', 'noise_level'])\"],\n",
    "    [\"preprocess(['df', 'is_train'])\", \"run(['X_train', 'y_train', 'X_val'])\"],\n",
    "    [\"target_mean_encoding_adaptive_smooth(['train_df', 'y', 'valid_df', 'col', 'n_splits', 'smoothing'])\", \"preprocess_basic(['df', 'is_train'])\", \"train(['X_train', 'y_train'])\"],\n",
    "    [\"add_spatial_features(['df', 'pickup_zone_col', 'dropoff_zone_col', 'pickup_centroids', 'dropoff_centroids'])\", \"train(['X_train', 'y_train'])\", \"prepare_val(['X_val', 'train_output'])\", \"predict(['train_output', 'prepare_val_output'])\"],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "f685470e-fa51-4f4a-8ced-063dd3843193",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MANUAL CODE ANALYSIS\n",
    "funcs_path = \"/home/flynn/src/junk/leakage-analysis/FILES/modular-1-flat-clean/\"\n",
    "old_path = \"FILES/modular-1-flat\"\n",
    "\n",
    "def load_code_file(func_sig):\n",
    "    files = df_ok[df_ok[\"n_funcs\"] == len(func_sig)][df_ok[\"func_sig\"].apply(lambda x: str(x) == str(func_sig))][\"html_file_path\"]\n",
    "    if len(files) == 0:\n",
    "        print(f\"func sig {func_sig} not found\")\n",
    "    for f in files.tolist():\n",
    "        fpath = funcs_path + f.replace(old_path, \"\")\n",
    "        if not os.path.exists(fpath):\n",
    "            print(f\"file {fpath} not found\")\n",
    "            return\n",
    "        print(fpath)\n",
    "        os.system(f\"xdg-open {fpath}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "3ce5fd7e-84f5-4839-85dc-5ae8e03431f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"train(['X_train', 'y_train'])\""
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ok[\"func_sig\"].iloc[4][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "ea41704a-da96-4cef-ab4f-2ffa212bec38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file /home/flynn/src/junk/leakage-analysis/FILES/modular-1-flat-clean//gpt-4.1-mini_Arab_ieor-242-nyc-taxi-Arab-python-0_1_submission_submission.html not found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_26319/2424617011.py:6: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  files = df_ok[df_ok[\"n_funcs\"] == len(func_sig)][df_ok[\"func_sig\"].apply(lambda x: str(x) == str(func_sig))][\"html_file_path\"]\n"
     ]
    }
   ],
   "source": [
    "load_code_file(LEAK_SIGS[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
